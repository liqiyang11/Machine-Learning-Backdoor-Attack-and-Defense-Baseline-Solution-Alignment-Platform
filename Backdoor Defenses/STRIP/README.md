\## STRIP

STRIP (Strong Intentional Perturbation) 是一种运行态（Run-time）的后门防御框架，旨在检测输入样本是否包含恶意触发器。它基于“后门攻击通常具有强烈的输入无关性（Input-agnostic）”这一核心观察：即无论背景图像如何变化，只要触发器存在，模型就会坚定地输出攻击者设定的目标类别。STRIP 的工作原理是对当前输入图像进行强烈的随机扰动（例如将输入图像与其他随机图像进行加权叠加），然后将生成的一组扰动样本送入模型预测。如果是干净样本，扰动会导致预测结果剧烈波动（高熵）；而如果是含有触发器的毒化样本，由于触发器的特征主导了模型的激活，预测结果会保持高度一致（低熵）。因此，通过计算预测分布的熵值，STRIP 可以高效地在推理阶段实时过滤掉攻击样本，且该方法与模型结构无关，无需访问训练数据或模型参数。



\## 使用

```

python STRIP.py

```

